{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset('penguins')\n",
    "penguins.dropna(inplace=True)\n",
    "X = np.array(penguins.drop(columns='species'))\n",
    "y = np.array(penguins['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss functions\n",
    "def gini_index(y):\n",
    "    size = len(y)\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    pmk = counts/size\n",
    "    \n",
    "    return np.sum(pmk*(1-pmk))\n",
    "\n",
    "def cross_entropy(y):\n",
    "    size = len(y)\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    pmk = counts/size\n",
    "    \n",
    "    return -np.sum(pmk * np.log2(pmk))\n",
    "\n",
    "def split_loss(child1, child2, loss=cross_entropy):\n",
    "    return (len(child1)*loss(child1) + len(child2)*loss(child2))/(len(child1) + len(child2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_rows_equal(X):\n",
    "    return (X == X[0]).all()\n",
    "\n",
    "def possible_splits(x):\n",
    "    L_values = []\n",
    "    for i in range(1, int(np.floor(len(x)/2)) + 1):\n",
    "        L_values.extend(list(combinations(x, i)))\n",
    "    \n",
    "    return L_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, Xsub, ysub, ID, obs, depth=0, parent_ID=None, leaf=True):\n",
    "        self.ID = ID\n",
    "        self.Xsub = Xsub\n",
    "        self.ysub = ysub\n",
    "        self.obs = obs\n",
    "        self.size = len(ysub)\n",
    "        self.depth = depth\n",
    "        self.parent_ID = parent_ID\n",
    "        self.leaf = leaf\n",
    "        \n",
    "class Splitter:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.loss = np.inf\n",
    "        self.no_split = True\n",
    "        \n",
    "        \n",
    "    def _replace_split(self, Xsub_d, loss, d, dtype='quant', t=None, L_values=None):\n",
    "        self.loss = loss\n",
    "        self.d = d\n",
    "        self.dtype = dtype\n",
    "        self.t = t\n",
    "        self.L_values = L_values\n",
    "        self.no_split = False\n",
    "        \n",
    "        if dtype == 'quant':\n",
    "            self.L_obs = self.obs[Xsub_d <= t]\n",
    "            self.R_obs = self.obs[Xsub_d > t]\n",
    "        else:\n",
    "            self.L_obs = self.obs[np.isin(Xsub_d, L_values)]\n",
    "            self.R_obs = self.obs[~np.isin(Xsub_d, L_values)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    \n",
    "    \"\"\"\n",
    "        FITTING METHODS\n",
    "    \"\"\"\n",
    "    def fit(self, X, y, loss_func=cross_entropy, max_depth=100, min_size=2, C=None):\n",
    "        \n",
    "        # Store data\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.N, self.D = self.X.shape\n",
    "        dtypes = [np.array(list(self.X[:, d])).dtype for d in range(self.D)]\n",
    "        self.dtypes = ['quant' if (dtype == float or dtype == int) else 'cat' for dtype in dtypes]\n",
    "            \n",
    "        # Regularization parameters\n",
    "        self.loss_func = loss_func\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.C = C\n",
    "        \n",
    "        # Initialize nodes\n",
    "        self.nodes_dict = {}\n",
    "        self.current_ID = 0\n",
    "        initial_node = Node(Xsub=X, ysub=y, ID=self.current_ID, obs=np.arange(self.N), parent_ID=None)\n",
    "        self.nodes_dict[self.current_ID] = initial_node\n",
    "        self.current_ID += 1\n",
    "        \n",
    "        # Build tree\n",
    "        self._build()\n",
    "        \n",
    "    def _build(self):\n",
    "        \n",
    "        eligible_buds = self.nodes_dict\n",
    "        for layer in range(self.max_depth):\n",
    "            \n",
    "            # find eligible nodes for layer iteration\n",
    "            eligible_buds = {\n",
    "                ID: node for (ID, node) in self.nodes_dict.items() if\n",
    "                                        (node.leaf == True) &\n",
    "                                        (node.size >= self.min_size) &\n",
    "                                        (~all_rows_equal(node.Xsub)) &\n",
    "                                        (len(np.unique(node.ysub)) > 1)\n",
    "            }\n",
    "            \n",
    "            if len(eligible_buds) == 0:\n",
    "                break\n",
    "                \n",
    "            for ID, bud in eligible_buds.items():\n",
    "                self._find_split(bud)\n",
    "                if not self.splitter.no_split: # could be no split for RF\n",
    "                    self._make_split()\n",
    "        \n",
    "    def _find_split(self, bud):\n",
    "        \n",
    "        splitter = Splitter()\n",
    "        splitter.bud_ID = bud.ID\n",
    "        splitter.obs = bud.obs\n",
    "        \n",
    "        # gather eligible predictors for Random Forests\n",
    "        if self.C is None:\n",
    "            eligible_predictors = np.arange(self.D)\n",
    "        else:\n",
    "            eligible_predictors = np.random.choice(np.arange(self.D), self.C, replace=False)\n",
    "            \n",
    "        for d in sorted(eligible_predictors):\n",
    "            Xsub_d = bud.Xsub[:, d]\n",
    "            dtype = self.dtypes[d]\n",
    "            if len(np.unique(Xsub_d)) == 1:\n",
    "                continue\n",
    "                \n",
    "            # for each threshold value\n",
    "            if dtype == 'quant':\n",
    "                for t in np.unique(Xsub_d)[:-1]:\n",
    "                    ysub_L = bud.ysub[Xsub_d <= t]\n",
    "                    ysub_R = bud.ysub[Xsub_d > t]\n",
    "                    \n",
    "                    loss = split_loss(ysub_L, ysub_R, loss=self.loss_func)\n",
    "                    if loss < splitter.loss:\n",
    "                        splitter._replace_split(Xsub_d, loss, d, dtype='quant', t=t)\n",
    "            else:\n",
    "                for L_values in possible_splits(np.unique(Xsub_d)):\n",
    "                    ysub_L = bud.ysub[np.isin(Xsub_d, L_values)]\n",
    "                    ysub_R = bud.ysub[~np.isin(Xsub_d, L_values)]\n",
    "                    \n",
    "                    loss = split_loss(ysub_L, ysub_R, loss=self.loss_func)\n",
    "                    if loss < splitter.loss:\n",
    "                        splitter._replace_split(Xsub_d, loss, d, 'cat', L_values=L_values)\n",
    "                    \n",
    "        self.splitter = splitter\n",
    "                        \n",
    "    def _make_split(self):\n",
    "        \n",
    "        parent_node = self.nodes_dict[self.splitter.bud_ID]\n",
    "        parent_node.leaf = False\n",
    "        parent_node.child_L = self.current_ID \n",
    "        parent_node.child_R = self.current_ID + 1\n",
    "        parent_node.d = self.splitter.d\n",
    "        parent_node.dtype = self.splitter.dtype\n",
    "        parent_node.t = self.splitter.t\n",
    "        parent_node.L_values = self.splitter.L_values\n",
    "        parent_node.L_obs, parent_node.R_obs = self.splitter.L_obs, self.splitter.R_obs\n",
    "        \n",
    "        if parent_node.dtype == 'quant':\n",
    "            L_condition = parent_node.Xsub[:, parent_node.d] <= parent_node.t\n",
    "        else:\n",
    "            L_condition = np.isin(parent_node.Xsub[:, parent_node.d], parent_node.L_values)\n",
    "        \n",
    "        Xchild_L = parent_node.Xsub[L_condition]\n",
    "        ychild_L = parent_node.ysub[L_condition]\n",
    "        Xchild_R = parent_node.Xsub[~L_condition]\n",
    "        ychild_R = parent_node.ysub[~L_condition]\n",
    "        \n",
    "        child_node_L = Node(Xchild_L, ychild_L, obs=parent_node.L_obs, depth=parent_node.depth+1,\n",
    "                            ID=self.current_ID, parent_ID=parent_node.ID)\n",
    "        \n",
    "        child_node_R = Node(Xchild_R, ychild_R, obs=parent_node.R_obs, depth=parent_node.depth+1,\n",
    "                            ID=self.current_ID+1, parent_ID=parent_node.ID)\n",
    "        \n",
    "        self.nodes_dict[self.current_ID] = child_node_L\n",
    "        self.nodes_dict[self.current_ID+1] = child_node_R\n",
    "        self.current_ID += 2\n",
    "        \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "        PREDICTING FUNCTIONS\n",
    "    \"\"\"\n",
    "    def _get_leaf_means(self):\n",
    "        self.leaf_means = {}\n",
    "        for node_ID, node in self.nodes_dict.items():\n",
    "            if node.leaf:\n",
    "                values, counts = np.unique(node.ysub, return_counts=True)\n",
    "                self.leaf_means[node_ID] = values[np.argmax(counts)]\n",
    "                \n",
    "    def predict(self, X_test):\n",
    "        self._get_leaf_means()\n",
    "        \n",
    "        yhat = []\n",
    "        for x in X_test:\n",
    "            node = self.nodes_dict[0]\n",
    "            while not node.leaf:\n",
    "                if node.dtype == 'quant':\n",
    "                    if x[node.d] <= node.t:\n",
    "                        node = self.nodes_dict[node.child_L]\n",
    "                    else:\n",
    "                        node = self.nodes_dict[node.child_R]\n",
    "                else:\n",
    "                    if x[node.d] in node.L_values:\n",
    "                        node = self.nodes_dict[node.child_L]\n",
    "                    else:\n",
    "                        node = self.nodes_dict[node.child_R]\n",
    "            yhat.append(self.leaf_means[node.ID])\n",
    "        \n",
    "        return np.array(yhat)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train, max_depth=10, min_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9404761904761905"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
